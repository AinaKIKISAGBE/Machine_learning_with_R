<!DOCTYPE HTML>
<!-- saved from url=(0078)https://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/ -->
<!DOCTYPE html PUBLIC "" ""><HTML lang="" lang="" xml:lang="" xmlns="http://www.w3.org/1999/xhtml"><HEAD><META 
content="IE=11.0000" http-equiv="X-UA-Compatible">
   
<META charset="utf-8">   
<META name="viewport" content="width=device-width, initial-scale=1">   
<META http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">   
<META name="GENERATOR" content="MSHTML 11.00.10570.1001">   
<STYLE type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </STYLE>
  <!--radix_placeholder_import_source-->  <!--/radix_placeholder_import_source--> 
  <!--radix_placeholder_meta_tags--> <TITLE>TensorFlow for R: Predicting Fraud 
with Autoencoders and Keras</TITLE> 
<META content="In this post we will train an autoencoder to detect credit card fraud. We will also demonstrate how to train Keras models in the cloud using CloudML. The basis of our model will be the Kaggle Credit Card Fraud Detection dataset." 
itemprop="description" property="description"> <LINK href="http://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/" 
rel="canonical"> <LINK href="https://creativecommons.org/licenses/by/4.0/" rel="license"> 
<LINK href="images/favicon.png" rel="icon" type="image/png"> <!--  https://schema.org/Article --> 
<META content="2018-01-25" itemprop="datePublished" 
property="article:published"> 
<META content="2018-01-25" itemprop="dateCreated" property="article:created"> 
<META name="article:author" content="Daniel Falbel"> <!--  https://developers.facebook.com/docs/sharing/webmasters#markup --> 
<META content="TensorFlow for R: Predicting Fraud with Autoencoders and Keras" 
property="og:title"> 
<META content="article" property="og:type"> 
<META content="In this post we will train an autoencoder to detect credit card fraud. We will also demonstrate how to train Keras models in the cloud using CloudML. The basis of our model will be the Kaggle Credit Card Fraud Detection dataset." 
property="og:description"> 
<META content="http://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/" 
property="og:url"> 
<META content="http://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/images/preview.png" 
property="og:image"> 
<META content="790" property="og:image:width"> 
<META content="537" property="og:image:height"> 
<META content="en_US" property="og:locale"> 
<META content="TensorFlow for R" property="og:site_name"> <!--  https://dev.twitter.com/cards/types/summary --> 
<META content="summary_large_image" property="twitter:card"> 
<META content="TensorFlow for R: Predicting Fraud with Autoencoders and Keras" 
property="twitter:title"> 
<META content="In this post we will train an autoencoder to detect credit card fraud. We will also demonstrate how to train Keras models in the cloud using CloudML. The basis of our model will be the Kaggle Credit Card Fraud Detection dataset." 
property="twitter:description"> 
<META content="http://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/" 
property="twitter:url"> 
<META content="http://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/images/preview.png" 
property="twitter:image"> 
<META content="790" property="twitter:image:width"> 
<META content="537" property="twitter:image:height"> <!--  https://scholar.google.com/intl/en/scholar/inclusion.html#indexing --> 
<META name="citation_title" content="TensorFlow for R: Predicting Fraud with Autoencoders and Keras"> 
<META name="citation_fulltext_html_url" content="http://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/"> 
<META name="citation_fulltext_world_readable" content=""> 
<META name="citation_online_date" content="2018/01/25"> 
<META name="citation_publication_date" content="2018/01/25"> 
<META name="citation_author" content="Daniel Falbel"> 
<META name="citation_author_institution" content="Curso-R"> <!--/radix_placeholder_meta_tags--> 
  <!--radix_placeholder_rmarkdown_metadata--> 
<SCRIPT id="radix-rmarkdown-metadata" type="text/json">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creative_commons","title","description","author","date","categories","preview","output","citation_url","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["CC BY"]},{"type":"character","attributes":{},"value":["Predicting Fraud with Autoencoders and Keras"]},{"type":"character","attributes":{},"value":["In this post we will train an autoencoder to detect credit card fraud. We will also demonstrate how to train Keras models in the cloud using CloudML. The basis of our model will be the Kaggle Credit Card Fraud Detection dataset."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url","affiliation","affiliation_url"]}},"value":[{"type":"character","attributes":{},"value":["Daniel Falbel"]},{"type":"character","attributes":{},"value":["https://github.com/dfalbel"]},{"type":"character","attributes":{},"value":["Curso-R"]},{"type":"character","attributes":{},"value":["http://curso-r.com/"]}]}]},{"type":"character","attributes":{},"value":["01-25-2018"]},{"type":"character","attributes":{},"value":["Keras","Examples","Autoencoders","Cloud"]},{"type":"character","attributes":{},"value":["images/preview.png"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["radix::radix_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"character","attributes":{},"value":["http://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/"]},{"type":"character","attributes":{},"value":["http://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/"]}]}
</SCRIPT>
 <!--/radix_placeholder_rmarkdown_metadata-->     
<SCRIPT id="radix-resource-manifest" type="text/json">
  {"type":"character","attributes":{},"value":["images/cloudml_report.png","images/joy-division.png","images/money.png","images/precision.png","images/preview.png","images/recall.png","keras-fraud-autoencoder_files/bowser-1.9.3/bowser.min.js","keras-fraud-autoencoder_files/distill-2.2.21/template.v2.js","keras-fraud-autoencoder_files/jquery-1.11.3/jquery.min.js","keras-fraud-autoencoder_files/webcomponents-2.0.0/webcomponents.js"]}
  </SCRIPT>
   <!--radix_placeholder_navigation_in_header--> 
<SCRIPT type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.radix-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</SCRIPT>
 
<STYLE type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.radix-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #455a64;
  font-size: 15px;
  font-weight: 300;
}

.radix-site-nav a {
  color: inherit;
  text-decoration: none;
}

.radix-site-nav a:hover {
  color: white;
}

@media print {
  .radix-site-nav {
    display: none;
  }
}

.radix-site-header {

}

.radix-site-footer {

}


/* Site Header */

.radix-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.radix-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .radix-site-header .nav-left {
    margin-left: 0;
  }
}


.radix-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.radix-site-header a,
.radix-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.radix-site-header .title {
  font-size: 18px;
}

.radix-site-header .logo {
  padding: 0;
}

.radix-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.radix-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .radix-site-header .logo img {
    display: inline-block;
  }
  .radix-site-header .nav-left {
    margin-left: 20px;
  }
  .radix-site-header .nav-right {
    margin-right: 20px;
  }
  .radix-site-header .title {
    padding-left: 12px;
  }
}


.radix-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .radix-site-header a, .radix-site-header .nav-dropdown  {display: none;}
  .radix-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .radix-site-header .title {
    margin-left: 0;
  }
  .radix-site-header .nav-right {
    margin-right: 0;
  }
  .radix-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .radix-site-header.responsive {position: relative;}
  .radix-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .radix-site-header.responsive a,
  .radix-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .radix-site-header.responsive .nav-left,
  .radix-site-header.responsive .nav-right {
    width: 100%;
  }
  .radix-site-header.responsive .nav-dropdown {float: none;}
  .radix-site-header.responsive .nav-dropdown-content {position: relative;}
  .radix-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.radix-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

</STYLE>
 <LINK href="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/all.css" 
rel="stylesheet"> <LINK href="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/v4-shims.css" 
rel="stylesheet"> 
<SCRIPT src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/headroom.min.js"></SCRIPT>
 <!--/radix_placeholder_navigation_in_header-->   <!--radix_placeholder_distill--> 
<STYLE type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

d-article {
  padding-bottom: 30px;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for table of contents */

.d-toc {
  color: rgba(0,0,0,0.8);
  font-size: 0.8em;
  line-height: 1em;
}

.d-toc-header {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  text-transform: uppercase;
  margin-top: 0;
  margin-bottom: 1.3em;
}

.d-toc a {
  border-bottom: none;
}

.d-toc ul {
  padding-left: 0;
}

.d-toc li>ul {
  padding-top: 0.8em;
  padding-left: 16px;
  margin-bottom: 0.6em;
}

.d-toc ul,
.d-toc li {
  list-style-type: none;
}

.d-toc li {
  margin-bottom: 0.9em;
}

.d-toc-separator {
  margin-top: 20px;
  margin-bottom: 2em;
}

.d-article-with-toc {
  border-top: none;
  padding-top: 0;
}



/* Tweak code blocks (note that this CSS is repeated above in an injection
   into the d-code shadow dom) */

pre.d-code code.d-code {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

pre.text-output {

  font-size: 12px;
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

@media(min-width: 768px) {
pre.d-code code.d-code  {
    padding-left: 18px;
    font-size: 14px;
}
pre.text-output {
  font-size: 14px;
}
}

/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure img {
  width: 100%;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}



/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}


/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

</STYLE>
 
<SCRIPT type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // create d-bibliography
  var bibliography = $('<d-bibliography></d-bibliography>');
  $('#distill-bibliography').wrap(bibliography);

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace citations with <d-cite>
  $('.citation').each(function(i, val) {
    appendix = true;
    var cites = $(this).attr('data-cites').split(" ");
    var dt_cite = $('<d-cite></d-cite>');
    dt_cite.attr('key', cites.join());
    $(this).replaceWith(dt_cite);
  });
  // remove refs
  $('#refs').remove();

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.text();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.text(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-toc a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // replace code blocks with d-code
  $('pre>code').each(function(i, val) {
    var code = $(this);
    var pre = code.parent();
    var clz = "";
    var language = pre.attr('class');
    if (language) {
      if ($.inArray(language, ["r", "cpp", "c", "java"]) != -1)
        language = "clike";
      language = ' language="' + language + '"';
      var dt_code = $('<d-code block' + language + clz + '></d-code>');
      dt_code.text(code.text());
      pre.replaceWith(dt_code);
    } else {
      code.addClass('text-output').unwrap().changeElementType('pre');
    }
  });

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('d-code, pre.text-output, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // table of contents
    if (have_authors) // adjust border if we are in authors
      $('.d-toc').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
    $('d-code').each(function(i, val) {
      var style = document.createElement('style');
      style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                        '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
      if (this.shadowRoot)
        this.shadowRoot.appendChild(style);
    });

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-toc-header').remove();
  $('.d-toc').remove();
  $('.d-toc-separator').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    $(this).find('img, .html-widget').css('width', '100%');
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.radix-site-header a').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');


  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</SCRIPT>
 <!--/radix_placeholder_distill-->   
<SCRIPT src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/jquery.min.js"></SCRIPT>
   
<SCRIPT src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/bowser.min.js"></SCRIPT>
   
<SCRIPT src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/webcomponents.js"></SCRIPT>
   
<SCRIPT src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/template.v2.js"></SCRIPT>
   <!--radix_placeholder_site_in_header--> 
<SCRIPT src="" async=""></SCRIPT>
 
<SCRIPT>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-102325748-2');
</SCRIPT>
 <!--/radix_placeholder_site_in_header--> </HEAD> 
<BODY><!--radix_placeholder_front_matter--> 
<SCRIPT id="distill-front-matter" type="text/json">
{"title":"Predicting Fraud with Autoencoders and Keras","description":"In this post we will train an autoencoder to detect credit card fraud. We will also demonstrate how to train Keras models in the cloud using CloudML. The basis of our model will be the Kaggle Credit Card Fraud Detection dataset.","authors":[{"author":"Daniel Falbel","authorURL":"https://github.com/dfalbel","affiliation":"Curso-R","affiliationURL":"http://curso-r.com/"}],"publishedDate":"2018-01-25T00:00:00.000-05:00","citationText":"Falbel, 2018"}
</SCRIPT>
 <!--/radix_placeholder_front_matter--> <!--radix_placeholder_navigation_before_body--> 
<HEADER class="header header--fixed" role="banner"><NAV class="radix-site-nav radix-site-header">
<DIV class="nav-left"><SPAN class="logo"><IMG src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/rstudio.png"> 
</SPAN> <A class="title" 
href="https://blogs.rstudio.com/tensorflow/index.html">TensorFlow for R Blog</A> 
</DIV>
<DIV class="nav-right"><A 
href="https://blogs.rstudio.com/tensorflow/index.html">Home</A> <A href="https://blogs.rstudio.com/tensorflow/about.html">About</A> 
<A 
href="https://blogs.rstudio.com/tensorflow/contributing.html">Contributing</A> 
<A href="https://blogs.rstudio.com/tensorflow/index.xml"><I 
class="fa fa-rss"></I> </A> <A class="nav-toggle" 
href="javascript:void(0);">☰</A></DIV></NAV></HEADER><!--/radix_placeholder_navigation_before_body--> <!--radix_placeholder_site_before_body--> <!--/radix_placeholder_site_before_body--> 
<DIV class="d-title">
<H1>Predicting Fraud with Autoencoders and Keras</H1>
<P>In this post we will train an autoencoder to detect credit card fraud. We 
will also demonstrate how to train Keras models in the cloud using CloudML. The 
basis of our model will be the Kaggle Credit Card Fraud Detection 
dataset.</P></DIV>
<DIV class="d-byline">  Daniel Falbel <A class="uri" href="https://github.com/dfalbel">https://github.com/dfalbel</A> 
(Curso-R)<A class="uri" href="http://curso-r.com/">http://curso-r.com/</A>   
<BR>01-25-2018 </DIV>
<DIV class="d-article">
<H2 id="overview">Overview</H2>
<P>In this post we will train an autoencoder to detect credit card fraud. We 
will also demonstrate how to train Keras models in the cloud using <A href="https://tensorflow.rstudio.com/tools/cloudml/">CloudML</A>.</P>
<P>The basis of our model will be the Kaggle <A href="https://www.kaggle.com/mlg-ulb/creditcardfraud">Credit 
Card Fraud Detection</A> dataset, which was collected during a research 
collaboration of Worldline and the <A href="http://mlg.ulb.ac.be/">Machine 
Learning Group</A> of ULB (Université Libre de Bruxelles) on big data mining and 
fraud detection.</P>
<P>The dataset contains credit card transactions by European cardholders made 
over a two day period in September 2013. There are 492 frauds out of 284,807 
transactions. The dataset is highly unbalanced, the positive class (frauds) 
account for only 0.172% of all transactions.</P>
<H2 id="reading-the-data">Reading the data</H2>
<P>After downloading the data from <A href="https://www.kaggle.com/dalpozz/creditcardfraud">Kaggle</A>, 
you can read it in to R with <CODE>read_csv()</CODE>:</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
library(readr)
df &lt;- read_csv("data-raw/creditcard.csv", col_types = list(Time = col_number()))</CODE></PRE></DIV>
<P>The input variables consist of only numerical values which are the result of 
a PCA transformation. In order to preserve confidentiality, no more information 
about the original features was provided. The features V1, …, V28 were obtained 
with PCA. There are however 2 features (<EM>Time</EM> and <EM>Amount</EM>) that 
were not transformed. <EM>Time</EM> is the seconds elapsed between each 
transaction and the first transaction in the dataset. <EM>Amount</EM> is the 
transaction amount and could be used for cost-sensitive learning. The 
<EM>Class</EM> variable takes value 1 in case of fraud and 0 otherwise.</P>
<H2 id="autoencoders">Autoencoders</H2>
<P>Since only 0.172% of the observations are frauds, we have a highly unbalanced 
classification problem. With this kind of problem, traditional classification 
approaches usually don’t work very well because we have only a very small sample 
of the rarer class.</P>
<P>An <A href="https://en.wikipedia.org/wiki/Autoencoder">autoencoder</A> is a 
neural network that is used to learn a representation (encoding) for a set of 
data, typically for the purpose of dimensionality reduction. For this problem we 
will train an autoencoder to encode non-fraud observations from our training 
set. Since frauds are supposed to have a different distribution then normal 
transactions, we expect that our autoencoder will have higher reconstruction 
errors on frauds then on normal transactions. This means that we can use the 
reconstruction error as a quantity that indicates if a transaction is fraudulent 
or not.</P>
<P>If you want to learn more about autoencoders, a good starting point is this 
<A href="https://www.youtube.com/watch?v=FzS3tMl4Nsc">video from Larochelle</A> 
on YouTube and <A href="http://www.deeplearningbook.org/contents/autoencoders.html">Chapter 
14</A> from the <A href="http://www.deeplearningbook.org/">Deep Learning</A> 
book by Goodfellow et al.</P>
<H2 id="visualization">Visualization</H2>
<P>For an autoencoder to work well we have a strong initial assumption: that the 
distribution of variables for normal transactions is different from the 
distribution for fraudulent ones. Let’s make some plots to verify this. 
Variables were transformed to a <CODE>[0,1]</CODE> interval for plotting.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggridges)
df %&gt;%
  gather(variable, value, -Class) %&gt;%
  ggplot(aes(y = as.factor(variable), 
             fill = as.factor(Class), 
             x = percent_rank(value))) +
  geom_density_ridges()</CODE></PRE></DIV>
<P><IMG src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/joy-division.png"></P>
<P>We can see that distributions of variables for fraudulent transactions are 
very different then from normal ones, except for the <EM>Time</EM> variable, 
which seems to have the exact same distribution.</P>
<H2 id="preprocessing">Preprocessing</H2>
<P>Before the modeling steps we need to do some preprocessing. We will split the 
dataset into train and test sets and then we will <A href="https://www.quora.com/What-is-the-meaning-of-min-max-normalization">Min-max 
normalize</A> our data (this is done because neural networks work much better 
with small input values). We will also remove the <EM>Time</EM> variable as it 
has the exact same distribution for normal and fraudulent transactions.</P>
<P>Based on the <EM>Time</EM> variable we will use the first 200,000 
observations for training and the rest for testing. This is good practice 
because when using the model we want to predict future frauds based on 
transactions that happened before.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
df_train &lt;- df %&gt;% filter(row_number(Time) &lt;= 200000) %&gt;% select(-Time)
df_test &lt;- df %&gt;% filter(row_number(Time) &gt; 200000) %&gt;% select(-Time)</CODE></PRE></DIV>
<P>Now let’s work on normalization of inputs. We created 2 functions to help us. 
The first one gets descriptive statistics about the dataset that are used for 
scaling. Then we have a function to perform the min-max scaling. It’s important 
to note that we applied the same normalization constants for training and test 
sets.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
library(purrr)

#' Gets descriptive statistics for every variable in the dataset.
get_desc &lt;- function(x) {
  map(x, ~list(
    min = min(.x),
    max = max(.x),
    mean = mean(.x),
    sd = sd(.x)
  ))
} 

#' Given a dataset and normalization constants it will create a min-max normalized
#' version of the dataset.
normalization_minmax &lt;- function(x, desc) {
  map2_dfc(x, desc, ~(.x - .y$min)/(.y$max - .y$min))
}</CODE></PRE></DIV>
<P>Now let’s create normalized versions of our datasets. We also transformed our 
data frames to matrices since this is the format expected by Keras.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
desc &lt;- df_train %&gt;% 
  select(-Class) %&gt;% 
  get_desc()

x_train &lt;- df_train %&gt;%
  select(-Class) %&gt;%
  normalization_minmax(desc) %&gt;%
  as.matrix()

x_test &lt;- df_test %&gt;%
  select(-Class) %&gt;%
  normalization_minmax(desc) %&gt;%
  as.matrix()

y_train &lt;- df_train$Class
y_test &lt;- df_test$Class</CODE></PRE></DIV>
<H1 id="model-definition">Model definition</H1>
<P>We will now define our model in Keras, a symmetric autoencoder with 4 dense 
layers.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
library(keras)
model &lt;- keras_model_sequential()
model %&gt;%
  layer_dense(units = 15, activation = "tanh", input_shape = ncol(x_train)) %&gt;%
  layer_dense(units = 10, activation = "tanh") %&gt;%
  layer_dense(units = 15, activation = "tanh") %&gt;%
  layer_dense(units = ncol(x_train))

summary(model)</CODE></PRE></DIV>
<PRE><CODE>
___________________________________________________________________________________
Layer (type)                         Output Shape                     Param #      
===================================================================================
dense_1 (Dense)                      (None, 15)                       450          
___________________________________________________________________________________
dense_2 (Dense)                      (None, 10)                       160          
___________________________________________________________________________________
dense_3 (Dense)                      (None, 15)                       165          
___________________________________________________________________________________
dense_4 (Dense)                      (None, 29)                       464          
===================================================================================
Total params: 1,239
Trainable params: 1,239
Non-trainable params: 0
___________________________________________________________________________________</CODE></PRE>
<P>We will then compile our model, using the mean squared error loss and the 
Adam optimizer for training.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
model %&gt;% compile(
  loss = "mean_squared_error", 
  optimizer = "adam"
)</CODE></PRE></DIV>
<H2 id="training-the-model">Training the model</H2>
<P>We can now train our model using the <CODE>fit()</CODE> function. Training 
the model is reasonably fast (~ 14s per epoch on my laptop). We will only feed 
to our model the observations of normal (non-fraudulent) transactions.</P>
<P>We will use <CODE>callback_model_checkpoint()</CODE> in order to save our 
model after each epoch. By passing the argument <CODE>save_best_only = 
TRUE</CODE> we will keep on disk only the epoch with smallest loss value on the 
test set. We will also use <CODE>callback_early_stopping()</CODE> to stop 
training if the validation loss stops decreasing for 5 epochs.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
checkpoint &lt;- callback_model_checkpoint(
  filepath = "model.hdf5", 
  save_best_only = TRUE, 
  period = 1,
  verbose = 1
)

early_stopping &lt;- callback_early_stopping(patience = 5)

model %&gt;% fit(
  x = x_train[y_train == 0,], 
  y = x_train[y_train == 0,], 
  epochs = 100, 
  batch_size = 32,
  validation_data = list(x_test[y_test == 0,], x_test[y_test == 0,]), 
  callbacks = list(checkpoint, early_stopping)
)</CODE></PRE></DIV>
<PRE><CODE>
Train on 199615 samples, validate on 84700 samples
Epoch 1/100
199615/199615 [==============================] - 17s 83us/step - loss: 0.0036 - val_loss: 6.8522e-04d from inf to 0.00069, saving model to model.hdf5
Epoch 2/100
199615/199615 [==============================] - 17s 86us/step - loss: 4.7817e-04 - val_loss: 4.7266e-04d from 0.00069 to 0.00047, saving model to model.hdf5
Epoch 3/100
199615/199615 [==============================] - 19s 94us/step - loss: 3.7753e-04 - val_loss: 4.2430e-04d from 0.00047 to 0.00042, saving model to model.hdf5
Epoch 4/100
199615/199615 [==============================] - 19s 94us/step - loss: 3.3937e-04 - val_loss: 4.0299e-04d from 0.00042 to 0.00040, saving model to model.hdf5
Epoch 5/100
199615/199615 [==============================] - 19s 94us/step - loss: 3.2259e-04 - val_loss: 4.0852e-04 improve
Epoch 6/100
199615/199615 [==============================] - 18s 91us/step - loss: 3.1668e-04 - val_loss: 4.0746e-04 improve
...</CODE></PRE>
<P>After training we can get the final loss for the test set by using the 
<CODE>evaluate()</CODE> fucntion.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
loss &lt;- evaluate(model, x = x_test[y_test == 0,], y = x_test[y_test == 0,])
loss</CODE></PRE></DIV>
<PRE><CODE>
        loss 
0.0003534254 </CODE></PRE>
<H2 id="tuning-with-cloudml">Tuning with CloudML</H2>
<P>We may be able to get better results by tuning our model hyperparameters. We 
can tune, for example, the normalization function, the learning rate, the 
activation functions and the size of hidden layers. CloudML uses Bayesian 
optimization to tune hyperparameters of models as described in <A href="https://cloud.google.com/blog/big-data/2017/08/hyperparameter-tuning-in-cloud-machine-learning-engine-using-bayesian-optimization">this 
blog post</A>.</P>
<P>We can use the <A 
href="https://tensorflow.rstudio.com/tools/cloudml/">cloudml package</A> to tune 
our model, but first we need to prepare our project by creating a <A href="https://tensorflow.rstudio.com/tools/training_flags.html">training 
flag</A> for each hyperparameter and a <CODE>tuning.yml</CODE> file that will 
tell CloudML what parameters we want to tune and how.</P>
<P>The full script used for training on CloudML can be found at <A class="uri" 
href="https://github.com/dfalbel/fraud-autoencoder-example">https://github.com/dfalbel/fraud-autoencoder-example</A>. 
The most important modifications to the code were adding the training flags:</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
FLAGS &lt;- flags(
  flag_string("normalization", "minmax", "One of minmax, zscore"),
  flag_string("activation", "relu", "One of relu, selu, tanh, sigmoid"),
  flag_numeric("learning_rate", 0.001, "Optimizer Learning Rate"),
  flag_integer("hidden_size", 15, "The hidden layer size")
)</CODE></PRE></DIV>
<P>We then used the <CODE>FLAGS</CODE> variable inside the script to drive the 
hyperparameters of the model, for example:</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
model %&gt;% compile(
  optimizer = optimizer_adam(lr = FLAGS$learning_rate), 
  loss = 'mean_squared_error',
)</CODE></PRE></DIV>
<P>We also created a <CODE>tuning.yml</CODE> file describing how hyperparameters 
should be varied during training, as well as what metric we wanted to optimize 
(in this case it was the validation loss: <CODE>val_loss</CODE>).</P>
<P><STRONG>tuning.yml</STRONG></P>
<PRE class="markup"><CODE>
trainingInput:
  scaleTier: CUSTOM
  masterType: standard_gpu
  hyperparameters:
    goal: MINIMIZE
    hyperparameterMetricTag: val_loss
    maxTrials: 10
    maxParallelTrials: 5
    params:
      - parameterName: normalization
        type: CATEGORICAL
        categoricalValues: [zscore, minmax]
      - parameterName: activation
        type: CATEGORICAL
        categoricalValues: [relu, selu, tanh, sigmoid]
      - parameterName: learning_rate
        type: DOUBLE
        minValue: 0.000001
        maxValue: 0.1
        scaleType: UNIT_LOG_SCALE
      - parameterName: hidden_size
        type: INTEGER
        minValue: 5
        maxValue: 50
        scaleType: UNIT_LINEAR_SCALE</CODE></PRE>
<P>We describe the type of machine we want to use (in this case a 
<CODE>standard_gpu</CODE> instance), the metric we want to minimize while 
tuning, and the the maximum number of trials (i.e.&nbsp;number of combinations 
of hyperparameters we want to test). We then specify how we want to vary each 
hyperparameter during tuning.</P>
<P>You can learn more about the tuning.yml file <A href="https://tensorflow.rstudio.com/tools/cloudml/articles/tuning.html">at 
the Tensorflow for R documentation</A> and at <A href="https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#HyperparameterSpec">Google’s 
official documentation on CloudML</A>.</P>
<P>Now we are ready to send the job to Google CloudML. We can do this by 
running:</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
library(cloudml)
cloudml_train("train.R", config = "tuning.yml")</CODE></PRE></DIV>
<P>The cloudml package takes care of uploading the dataset and installing any R 
package dependencies required to run the script on CloudML. If you are using 
RStudio v1.1 or higher, it will also allow you to monitor your job in a 
background terminal. You can also monitor your job using the <A href="https://console.cloud.google.com/">Google 
Cloud Console</A>.</P>
<P>After the job is finished we can collect the job results with:</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
job_collect()</CODE></PRE></DIV>
<P>This will copy the files from the job with the best <CODE>val_loss</CODE> 
performance on CloudML to your local system and open a report summarizing the 
training run.</P>
<P><IMG style="border: 1px solid rgba(0, 0, 0, 0.1); border-image: none;" src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/cloudml_report.png"></P>
<P>Since we used a callback to save model checkpoints during training, the model 
file was also copied from Google CloudML. Files created during training are 
copied to the “runs” subdirectory of the working directory from which 
<CODE>cloudml_train()</CODE> is called. You can determine this directory for the 
most recent run with:</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
latest_run()$run_dir</CODE></PRE></DIV>
<PRE><CODE>
[1] runs/cloudml_2018_01_23_221244595-03</CODE></PRE>
<P>You can also list all previous runs and their validation losses with:</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
ls_runs(order = metric_val_loss, decreasing = FALSE)</CODE></PRE></DIV>
<PRE><CODE>
                    run_dir metric_loss metric_val_loss
1 runs/2017-12-09T21-01-11Z      0.2577          0.1482
2 runs/2017-12-09T21-00-11Z      0.2655          0.1505
3 runs/2017-12-09T19-59-44Z      0.2597          0.1402
4 runs/2017-12-09T19-56-48Z      0.2610          0.1459

Use View(ls_runs()) to view all columns</CODE></PRE>
<P>In our case the job downloaded from CloudML was saved to 
<CODE>runs/cloudml_2018_01_23_221244595-03/</CODE>, so the saved model file is 
available at <CODE>runs/cloudml_2018_01_23_221244595-03/model.hdf5</CODE>. We 
can now use our tuned model to make predictions.</P>
<H2 id="making-predictions">Making predictions</H2>
<P>Now that we trained and tuned our model we are ready to generate predictions 
with our autoencoder. We are interested in the MSE for each observation and we 
expect that observations of fraudulent transactions will have higher MSE’s.</P>
<P>First, let’s load our model.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
model &lt;- load_model_hdf5("runs/cloudml_2018_01_23_221244595-03/model.hdf5", 
                         compile = FALSE)</CODE></PRE></DIV>
<P>Now let’s calculate the MSE for the training and test set observations.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
pred_train &lt;- predict(model, x_train)
mse_train &lt;- apply((x_train - pred_train)^2, 1, sum)

pred_test &lt;- predict(model, x_test)
mse_test &lt;- apply((x_test - pred_test)^2, 1, sum)</CODE></PRE></DIV>
<P>A good measure of model performance in highly unbalanced datasets is the Area 
Under the ROC Curve (AUC). AUC has a nice interpretation for this problem, it’s 
the probability that a fraudulent transaction will have higher MSE then a normal 
one. We can calculate this using the <A href="https://cran.r-project.org/package=Metrics">Metrics</A> 
package, which implements a wide variety of common machine learning model 
performance metrics.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
library(Metrics)
auc(y_train, mse_train)
auc(y_test, mse_test)</CODE></PRE></DIV>
<PRE><CODE>
[1] 0.9546814
[1] 0.9403554</CODE></PRE>
<P>To use the model in practice for making predictions we need to find a 
threshold <SPAN class="math inline">\(k\)</SPAN> for the MSE, then if if <SPAN 
class="math inline">\(MSE &gt; k\)</SPAN> we consider that transaction a fraud 
(otherwise we consider it normal). To define this value it’s useful to look at 
precision and recall while varying the threshold <SPAN 
class="math inline">\(k\)</SPAN>.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
possible_k &lt;- seq(0, 0.5, length.out = 100)
precision &lt;- sapply(possible_k, function(k) {
  predicted_class &lt;- as.numeric(mse_test &gt; k)
  sum(predicted_class == 1 &amp; y_test == 1)/sum(predicted_class)
})

qplot(possible_k, precision, geom = "line") 
  + labs(x = "Threshold", y = "Precision")</CODE></PRE></DIV>
<P><IMG src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/precision.png"></P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
recall &lt;- sapply(possible_k, function(k) {
  predicted_class &lt;- as.numeric(mse_test &gt; k)
  sum(predicted_class == 1 &amp; y_test == 1)/sum(y_test)
})
qplot(possible_k, recall, geom = "line") 
  + labs(x = "Threshold", y = "Recall")</CODE></PRE></DIV>
<P><IMG src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/recall.png"></P>
<P>A good starting point would be to choose the threshold with maximum precision 
but we could also base our decision on how much money we might lose from 
fraudulent transactions.</P>
<P>Suppose each manual verification of fraud costs us $1 but if we don’t verify 
a transaction and it’s a fraud we will lose this transaction amount. Let’s find 
for each threshold value how much money we would lose.</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
cost_per_verification &lt;- 1

lost_money &lt;- sapply(possible_k, function(k) {
  predicted_class &lt;- as.numeric(mse_test &gt; k)
  sum(cost_per_verification * predicted_class + (predicted_class == 0) * y_test * df_test$Amount) 
})

qplot(possible_k, lost_money, geom = "line") + labs(x = "Threshold", y = "Lost Money")</CODE></PRE></DIV>
<P><IMG src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/money.png"></P>
<P>We can find the best threshold in this case with:</P>
<DIV class="layout-chunk" data-layout="l-body">
<PRE class="r"><CODE>
possible_k[which.min(lost_money)]</CODE></PRE></DIV>
<PRE><CODE>
[1] 0.005050505</CODE></PRE>
<P>If we needed to manually verify all frauds, it would cost us ~$13,000. Using 
our model we can reduce this to ~$2,500.</P><!--radix_placeholder_article_footer--> 
<DIV class="article-footer">
<P class="social_footer"><SPAN class="disqus-comments"><I class="fas fa-comments"></I> 
     &nbsp;       <SPAN class="disqus-comment-count" data-disqus-identifier="posts/2018-01-24-keras-fraud-autoencoder/">Comment 
on this article</SPAN>     </SPAN>     <SPAN class="article-sharing">      
Share: &nbsp;       <A href="https://twitter.com/share?text=Predicting%20Fraud%20with%20Autoencoders%20and%20Keras&amp;url=http%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2018-01-24-keras-fraud-autoencoder%2F"><I 
class="fab fa-twitter"></I>       </A>       <A href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3A%2F%2Fblogs.rstudio.com%2Ftensorflow%2Fposts%2F2018-01-24-keras-fraud-autoencoder%2F&amp;title=Predicting%20Fraud%20with%20Autoencoders%20and%20Keras"><I 
class="fab fa-linkedin"></I>       </A>     </SPAN>   </P>
<SCRIPT id="dsq-count-scr" src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/count.js" async=""></SCRIPT>
   
<DIV class="hidden" id="disqus_thread"></DIV>
<SCRIPT>
var disqus_config = function () {
  this.page.url = 'http://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/';
  this.page.identifier = 'posts/2018-01-24-keras-fraud-autoencoder/';
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = 'https://tensorflow-for-r-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</SCRIPT>
   
<P>
<DIV class="subscribe">
<DIV id="subscribe-caption" style="line-height: 1.2; margin-bottom: 2px;">Enjoy 
this blog? Get notified of new posts by email:</DIV>
<SCRIPT src="TensorFlow%20for%20R%20Predicting%20Fraud%20with%20Autoencoders%20and%20Keras_fichiers/forms2.min.js"></SCRIPT>
 
<FORM class="mtktoBlogEmailForm" id="mktoForm_2224"></FORM>
<SCRIPT>

// establish metrics based on where the form is located
var in_sidebar = $('#subscribe-caption').parents('.sidebar-section').length;
if (in_sidebar) {
  var form_width = 190;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '';
  var font_size = '12px';
} else {
  var form_width = 400;
  var base_width = form_width - 23;
  var email_width = base_width + 'px';
  var label_width = (base_width - 20) + 'px';
  var button_width = email_width;
  var button_padding = '30px';
  var button_margin = '12px';
  var font_size = '15px';
}

$('#subscribe-caption')
  .css('width', base_width)
  .css('font-size', font_size);


MktoForms2.loadForm("https://app-ab02.marketo.com", "709-NXN-706", 2224, function(form) {

  // get jquery reference to form
  form = $(form.getFormElem().get(0));

  $(form).css('width', form_width + 'px');
  $(form).find('.mktoOffset').remove();
  $(form).find('.mktoGutter').remove();
  $(form).find('.mktoEmailField').css('width', email_width);
  $(form).find('.mktoLabel').children().attr('style', 'font-weight: 400');
  $(form).find('.mktoLabel')
      .css('width', label_width)
      .css('font-size', font_size);
  $(form).find('.mktoButtonRow')
      .css('width', button_width)
      .css('text-align', 'center');
  $(form).find('.mktoButtonWrap').attr('style', '');
  $(form).find('.mktoButton')
      .css('margin-top', '10px')
      .css('padding-left', button_padding)
      .css('padding-right', button_padding)
      .css('font-size', font_size)
      .css('margin-top', button_margin);
});
</SCRIPT>
 </DIV>
<P></P></DIV><!--/radix_placeholder_article_footer--> </DIV>
<DIV class="d-appendix"></DIV><!-- dynamically load mathjax for compatibility with self-contained --> 
<SCRIPT>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</SCRIPT>
 <!--radix_placeholder_site_after_body--> <!--/radix_placeholder_site_after_body--> <!--radix_placeholder_appendices--> 
<DIV class="appendix-bottom">
<H3 id="reuse">Reuse</H3>
<P>Text and figures are licensed under Creative Commons Attribution <A href="https://creativecommons.org/licenses/by/4.0/" 
rel="license">CC BY 4.0</A>. The figures that have been reused from other 
sources don't fall under this license and can be recognized by a note in their 
caption: "Figure from ...".</P>
<H3 id="citation">Citation</H3>
<P>For attribution, please cite this work as</P>
<PRE class="citation-appendix short">Falbel (2018, Jan. 25). TensorFlow for R: Predicting Fraud with Autoencoders and Keras. Retrieved from http://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/</PRE>
<P>BibTeX citation</P>
<PRE class="citation-appendix long">@misc{falbel2018predicting,
  author = {Falbel, Daniel},
  title = {TensorFlow for R: Predicting Fraud with Autoencoders and Keras},
  url = {http://blogs.rstudio.com/tensorflow/posts/2018-01-24-keras-fraud-autoencoder/},
  year = {2018}
}</PRE></DIV><!--/radix_placeholder_appendices--> <!--radix_placeholder_navigation_after_body--> <!--/radix_placeholder_navigation_after_body--> 
</BODY></HTML>
